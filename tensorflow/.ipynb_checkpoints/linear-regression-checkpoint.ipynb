{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простейшая линейная регрессия\n",
    "    датасет - Бостонская недвижимость\n",
    "    \n",
    "    \n",
    "    CRIM per capita crime rate by town\n",
    "    ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    INDUS proportion of non-retail business acres per town\n",
    "    CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "    NOX nitric oxides concentration (parts per 10 million)\n",
    "    RM average number of rooms per dwelling\n",
    "    AGE proportion of owner-occupied units built prior to 1940\n",
    "    DIS weighted distances to five Boston employment centres\n",
    "    RAD index of accessibility to radial highways\n",
    "    TAX full-value property-tax rate per $10,000 \n",
    "    \n",
    "    PTRATIO pupil-teacher ratio by town\n",
    "    B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    LSTAT % lower status of the population\n",
    "    MEDV Median value of owner-occupied homes in $1000’s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "dataset['data'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[9.72418e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.85960e+02\n",
      "  1.95200e+01]\n",
      " [2.79570e-01 0.00000e+00 9.69000e+00 ... 1.92000e+01 3.96900e+02\n",
      "  1.35900e+01]\n",
      " [1.36781e+01 0.00000e+00 1.81000e+01 ... 2.02000e+01 6.89500e+01\n",
      "  3.40200e+01]\n",
      " ...\n",
      " [1.25790e-01 4.50000e+01 3.44000e+00 ... 1.52000e+01 3.82840e+02\n",
      "  4.56000e+00]\n",
      " [1.80028e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.27610e+02\n",
      "  1.21400e+01]\n",
      " [3.75780e-01 0.00000e+00 1.05900e+01 ... 1.86000e+01 3.95240e+02\n",
      "  2.39800e+01]], shape=(404, 13), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset['data'], dataset['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train = tf.constant(X_train, dtype=tf.float32)\n",
    "X_test = tf.constant(X_test, dtype=tf.float32)\n",
    "y_train = tf.constant(y_train, dtype=tf.float32)\n",
    "y_test = tf.constant(y_test, dtype=tf.float32)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial losses: MSE:[295817.3], MAE:[523.6076], Huber:523.1076049804688\n"
     ]
    }
   ],
   "source": [
    "# инициализация\n",
    "initializer = tf.keras.initializers.he_normal()\n",
    "\n",
    "W0 = tf.Variable(initializer(shape=(1, 13)), shape=(1,13), dtype=tf.float32)\n",
    "b0 = tf.Variable([[0.]], shape=(1,1), dtype=tf.float32)\n",
    "\n",
    "W, b = W0, b0\n",
    "\n",
    "h = tf.keras.losses.Huber()\n",
    "initial_mse = tf.keras.losses.mse(W @ tf.transpose(X_test) + b, y_test) \n",
    "initial_mae = tf.keras.losses.mae(W @ tf.transpose(X_test) + b, y_test) \n",
    "initial_huber = h(W @ tf.transpose(X_test) + b, y_test) \n",
    "print(\"Initial losses: MSE:{}, MAE:{}, Huber:{}\". format(initial_mse, initial_mae, initial_huber))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Iter: 0 ------\n",
      "Train losses: MSE:[278689.6], MAE:[508.5758], Huber:508.0758056640625\n",
      "Test losses: MSE:[292486.38], MAE:[520.5928], Huber:520.0927734375\n",
      "----- Iter: 1000 ------\n",
      "Train losses: MSE:[509.13538], MAE:[15.698313], Huber:15.209028244018555\n",
      "Test losses: MSE:[379.65515], MAE:[14.344528], Huber:13.845393180847168\n",
      "----- Iter: 2000 ------\n",
      "Train losses: MSE:[380.38373], MAE:[13.902361], Huber:13.410933494567871\n",
      "Test losses: MSE:[299.4817], MAE:[12.837703], Huber:12.34174919128418\n",
      "----- Iter: 3000 ------\n",
      "Train losses: MSE:[296.43695], MAE:[12.376311], Huber:11.886895179748535\n",
      "Test losses: MSE:[245.59767], MAE:[11.414646], Huber:10.918208122253418\n",
      "----- Iter: 4000 ------\n",
      "Train losses: MSE:[237.2587], MAE:[11.119163], Huber:10.632485389709473\n",
      "Test losses: MSE:[210.37675], MAE:[10.401517], Huber:9.909993171691895\n",
      "----- Iter: 5000 ------\n",
      "Train losses: MSE:[198.66232], MAE:[10.142804], Huber:9.656201362609863\n",
      "Test losses: MSE:[188.2243], MAE:[9.849783], Huber:9.359939575195312\n",
      "----- Iter: 6000 ------\n",
      "Train losses: MSE:[178.77222], MAE:[9.466049], Huber:8.985103607177734\n",
      "Test losses: MSE:[173.47887], MAE:[9.2370405], Huber:8.745332717895508\n",
      "----- Iter: 7000 ------\n",
      "Train losses: MSE:[165.85143], MAE:[9.073218], Huber:8.58958911895752\n",
      "Test losses: MSE:[163.05235], MAE:[8.851146], Huber:8.3661470413208\n",
      "----- Iter: 8000 ------\n",
      "Train losses: MSE:[159.50558], MAE:[8.833749], Huber:8.351290702819824\n",
      "Test losses: MSE:[156.34723], MAE:[8.495602], Huber:8.020198822021484\n",
      "----- Iter: 9000 ------\n",
      "Train losses: MSE:[152.47592], MAE:[8.669207], Huber:8.185635566711426\n",
      "Test losses: MSE:[149.9181], MAE:[8.33143], Huber:7.858471393585205\n",
      "----- Iter: 10000 ------\n",
      "Train losses: MSE:[146.9304], MAE:[8.527656], Huber:8.047820091247559\n",
      "Test losses: MSE:[144.41133], MAE:[8.164371], Huber:7.694405555725098\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "\n",
    "def print_losses(X_train, y_train, X_test, y_test, i):\n",
    "    mse = tf.keras.losses.mse((W @ tf.transpose(X_train) + b), y_train) \n",
    "    mae = tf.keras.losses.mae((W @ tf.transpose(X_train) + b), y_train) \n",
    "    huber = h((W @ tf.transpose(X_train) + b), y_train) \n",
    "    print('----- Iter: {} ------'.format(i))\n",
    "    print(\"Train losses: MSE:{}, MAE:{}, Huber:{}\". format(mse, mae, huber))\n",
    "    \n",
    "    mse = tf.keras.losses.mse((W @ tf.transpose(X_test) + b), y_test) \n",
    "    mae = tf.keras.losses.mae((W @ tf.transpose(X_test) + b), y_test) \n",
    "    huber = h((W @ tf.transpose(X_test) + b), y_test) \n",
    "    print(\"Test losses: MSE:{}, MAE:{}, Huber:{}\". format(mse, mae, huber))    \n",
    "\n",
    "for i in range(10001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(W)\n",
    "        tape.watch(b)\n",
    "        loss = tf.keras.losses.mae(W @ tf.transpose(X_train) + b, y_train)\n",
    "        \n",
    "    dW, db = tape.gradient(loss, [W,b])    \n",
    "\n",
    "    W = W - lr * dW\n",
    "    b = b - lr * db\n",
    "    if i % 1000 == 0:\n",
    "        print_losses(X_train, y_train, X_test, y_test, i)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# а если оптимайзером?\n",
    "# на тех же итерациях реально сильно круче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Iter: 0 ------\n",
      "Train losses: MSE:[663.63983], MAE:[18.349384], Huber:17.852901458740234\n",
      "Test losses: MSE:[486.8301], MAE:[14.947463], Huber:14.456467628479004\n",
      "----- Iter: 1000 ------\n",
      "Train losses: MSE:[119.61671], MAE:[7.317955], Huber:6.84630012512207\n",
      "Test losses: MSE:[104.43905], MAE:[6.4479156], Huber:5.968722343444824\n",
      "----- Iter: 2000 ------\n",
      "Train losses: MSE:[53.977535], MAE:[4.985423], Huber:4.52485466003418\n",
      "Test losses: MSE:[48.589146], MAE:[4.5617285], Huber:4.101846694946289\n",
      "----- Iter: 3000 ------\n",
      "Train losses: MSE:[32.174797], MAE:[3.6498275], Huber:3.196946620941162\n",
      "Test losses: MSE:[26.827364], MAE:[3.4010084], Huber:2.9418368339538574\n",
      "----- Iter: 4000 ------\n",
      "Train losses: MSE:[27.695234], MAE:[3.2548783], Huber:2.815298557281494\n",
      "Test losses: MSE:[22.58129], MAE:[3.1088185], Huber:2.655048370361328\n",
      "----- Iter: 5000 ------\n",
      "Train losses: MSE:[27.141138], MAE:[3.1768181], Huber:2.740269422531128\n",
      "Test losses: MSE:[22.49558], MAE:[3.0827534], Huber:2.625678777694702\n",
      "----- Iter: 6000 ------\n",
      "Train losses: MSE:[27.136042], MAE:[3.1515152], Huber:2.7106010913848877\n",
      "Test losses: MSE:[22.681723], MAE:[3.1059275], Huber:2.655097246170044\n",
      "----- Iter: 7000 ------\n",
      "Train losses: MSE:[27.225992], MAE:[3.1435995], Huber:2.699981451034546\n",
      "Test losses: MSE:[22.748592], MAE:[3.1072268], Huber:2.660597562789917\n",
      "----- Iter: 8000 ------\n",
      "Train losses: MSE:[27.186695], MAE:[3.1415157], Huber:2.6951942443847656\n",
      "Test losses: MSE:[22.767662], MAE:[3.1103542], Huber:2.664638042449951\n",
      "----- Iter: 9000 ------\n",
      "Train losses: MSE:[27.256502], MAE:[3.1390078], Huber:2.693103075027466\n",
      "Test losses: MSE:[22.821419], MAE:[3.1127663], Huber:2.665584087371826\n"
     ]
    }
   ],
   "source": [
    "W, b = W0, b0\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "for i in range(10000):\n",
    "    opt.minimize(lambda: tf.keras.losses.mae(W @ tf.transpose(X_train) + b, y_train),\n",
    "                var_list = [W, b])\n",
    "    if i % 1000 == 0:\n",
    "        print_losses(X_train, y_train, X_test, y_test, i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
